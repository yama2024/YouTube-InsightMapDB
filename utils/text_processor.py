import logging
from youtube_transcript_api import YouTubeTranscriptApi
import google.generativeai as genai
import re
import os
import time
from typing import List, Optional, Dict, Any, Tuple, Callable
from cachetools import TTLCache, cached
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
    RetryError
)

# Enhanced logging setup
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class APIError(Exception):
    """Base class for API related errors"""
    pass

class ConnectionError(APIError):
    """Error when connection to API fails"""
    pass

class TimeoutError(APIError):
    """Error when API request times out"""
    pass

class QuotaExceededError(APIError):
    """Error when API quota is exceeded"""
    pass

class InvalidInputError(APIError):
    """Error when input is invalid"""
    pass

class TextProcessor:
    def __init__(self):
        api_key = os.environ.get('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("Gemini API key is not set in environment variables")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro')
        
        # Initialize caches
        self.subtitle_cache = TTLCache(maxsize=100, ttl=3600)  # 1 hour TTL
        self.processed_text_cache = TTLCache(maxsize=100, ttl=1800)  # 30 minutes TTL
        
        # Enhanced noise patterns for Japanese text
        self.noise_patterns = {
            'timestamps': r'\[?\(?\d{1,2}:\d{2}(?::\d{2})?\]?\)?',
            'speaker_tags': r'\[[^\]]*\]|\([^)]*\)',
            'filler_words': r'\b(ãˆãƒ¼ã¨|ãˆã£ã¨|ãˆãƒ¼|ã‚ã®|ã‚ã®ãƒ¼|ã¾ã|ã‚“ãƒ¼|ãã®ãƒ¼|ãªã‚“ã‹|ã“ã†|ã­|ã­ã‡|ã•ã|ã†ãƒ¼ã‚“|ã‚ãƒ¼|ãã†ã§ã™ã­|ã¡ã‚‡ã£ã¨)\b',
            'repeated_chars': r'([^\W\d_])\1{3,}',
            'multiple_spaces': r'[\sã€€]{2,}',
            'empty_lines': r'\n\s*\n',
            'punctuation': r'([ã€‚ï¼ï¼ï¼Ÿ])\1+',
            'noise_symbols': r'[â™ªâ™«â™¬â™©â€ â€¡â—Šâ—†â—‡â– â–¡â–²â–³â–¼â–½â—‹â—â—]',
            'parentheses': r'ï¼ˆ[^ï¼‰]*ï¼‰|\([^)]*\)',
            'unnecessary_symbols': r'[ï¼Šâˆ—â€»#ï¼ƒâ˜…â˜†â–ºâ–·â—â—€â†’â†â†‘â†“]',
            'commercial_markers': r'(?:CM|åºƒå‘Š|ã‚¹ãƒãƒ³ã‚µãƒ¼)(?:\s*\d*)?',
            'system_messages': r'(?:ã‚·ã‚¹ãƒ†ãƒ |ã‚¨ãƒ©ãƒ¼|é€šçŸ¥)(?:ï¼š|:).*?(?:\n|$)',
            'automated_tags': r'\[(?:éŸ³æ¥½|æ‹æ‰‹|ç¬‘|BGM|SE|åŠ¹æœéŸ³)\]'
        }
        
        # Japanese text normalization
        self.jp_normalization = {
            'spaces': {
                'ã€€': ' ',
                '\u3000': ' ',
                '\xa0': ' '
            },
            'punctuation': {
                'ï¼': 'ã€‚',
                'â€¦': 'ã€‚',
                '.': 'ã€‚',
                'ï½¡': 'ã€‚',
                'ï½¤': 'ã€'
            }
        }

    def _clean_text(self, text: str, progress_callback: Optional[Callable] = None) -> str:
        """Enhanced text cleaning with progress tracking"""
        if not text:
            return ""
        
        try:
            total_steps = len(self.jp_normalization) + len(self.noise_patterns) + 1
            current_step = 0
            
            # Normalize Japanese text
            for category, replacements in self.jp_normalization.items():
                for old, new in replacements.items():
                    text = text.replace(old, new)
                current_step += 1
                if progress_callback:
                    progress_callback(current_step / total_steps, f"æ­£è¦åŒ–å‡¦ç†ä¸­: {category}")
            
            # Remove noise patterns
            for pattern_name, pattern in self.noise_patterns.items():
                text = re.sub(pattern, '', text)
                current_step += 1
                if progress_callback:
                    progress_callback(current_step / total_steps, f"ãƒã‚¤ã‚ºé™¤å»ä¸­: {pattern_name}")
            
            # Improve sentence structure
            text = self._improve_sentence_structure(text)
            current_step += 1
            if progress_callback:
                progress_callback(1.0, "æ–‡ç« æ§‹é€ ã®æœ€é©åŒ–å®Œäº†")
            
            return text
            
        except Exception as e:
            logger.error(f"ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return text

    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1.5, min=4, max=60),
        retry=(
            retry_if_exception_type(ConnectionError) |
            retry_if_exception_type(TimeoutError) |
            retry_if_exception_type(APIError)
        ),
        before_sleep=before_sleep_log(logger, logging.INFO)
    )
    def generate_summary(self, text: str, progress_callback: Optional[Callable] = None) -> str:
        """Generate AI summary with enhanced error handling and retry mechanism"""
        if not text:
            raise InvalidInputError("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™")
            
        try:
            if progress_callback:
                progress_callback(0.1, "ğŸ” ãƒ†ã‚­ã‚¹ãƒˆè§£æã‚’é–‹å§‹ã—ã¦ã„ã¾ã™")
            
            prompt = f"""
# ã‚ãªãŸã®ç›®çš„:
å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®åŒ…æ‹¬çš„ãªè¦ç´„ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

# ãƒ«ãƒ¼ãƒ«:
1. è¦ç´„ã¯ä»¥ä¸‹ã®æ§‹é€ ã§ä½œæˆ:
   - æ¦‚è¦ï¼ˆå…¨ä½“ã®è¦ç‚¹ï¼‰
   - ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆï¼ˆç®‡æ¡æ›¸ãï¼‰
   - è©³ç´°ãªåˆ†æï¼ˆé‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã”ã¨ï¼‰
   - çµè«–

2. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
   - Markdownå½¢å¼ã§å‡ºåŠ›
   - è¦‹å‡ºã—ã¯é©åˆ‡ãªãƒ¬ãƒ™ãƒ«ã§
   - é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯å¼·èª¿
   - ç®‡æ¡æ›¸ãã‚’åŠ¹æœçš„ã«ä½¿ç”¨

å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ:
{text}
"""
            
            if progress_callback:
                progress_callback(0.3, "ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œä¸­...")
            
            try:
                # Set timeout and validate response
                start_time = time.time()
                response = self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.3,
                        top_p=0.8,
                        top_k=40,
                        max_output_tokens=8192,
                    ),
                    timeout=120  # 2 minutes timeout
                )
                
                if not response.text:
                    raise APIError("AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™")
                
                processing_time = time.time() - start_time
                logger.info(f"AIç”Ÿæˆå®Œäº† (å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’)")
                
                if progress_callback:
                    progress_callback(0.7, "ğŸ“ è¦ç´„ã‚’æ•´å½¢ä¸­...")
                
                summary = response.text
                
                # Post-processing with error handling
                try:
                    summary = self._clean_text(summary)
                    summary = self._improve_sentence_structure(summary)
                except Exception as e:
                    logger.warning(f"è¦ç´„ã®å¾Œå‡¦ç†ä¸­ã«è­¦å‘Š: {str(e)}")
                
                if progress_callback:
                    progress_callback(1.0, "âœ¨ è¦ç´„ãŒå®Œäº†ã—ã¾ã—ãŸ")
                
                return summary
                
            except Exception as e:
                error_msg = str(e).lower()
                if "timeout" in error_msg:
                    raise TimeoutError("APIå¿œç­”ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
                elif "quota" in error_msg:
                    raise QuotaExceededError("APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                elif "connection" in error_msg:
                    raise ConnectionError("APIæ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                else:
                    raise APIError(f"AIç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
                
        except RetryError as e:
            logger.error(f"ãƒªãƒˆãƒ©ã‚¤å¾Œã‚‚è¦ç´„ç”Ÿæˆã«å¤±æ•—: {str(e)}")
            if progress_callback:
                progress_callback(1.0, "âŒ è¦ç´„ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            raise APIError("è¤‡æ•°å›ã®è©¦è¡Œå¾Œã‚‚è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            
        except Exception as e:
            logger.error(f"è¦ç´„å‡¦ç†ä¸­ã«é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            if progress_callback:
                progress_callback(1.0, "âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            raise APIError(f"è¦ç´„å‡¦ç†ã‚¨ãƒ©ãƒ¼: {self._get_user_friendly_error_message(str(e))}")

    def _improve_sentence_structure(self, text: str) -> str:
        """Improve Japanese sentence structure and readability"""
        try:
            # Fix sentence endings
            text = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*(?=[^ã€ã€ï¼‰])', r'\1\n', text)
            
            # Improve paragraph breaks
            text = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*\n\s*([^ã€Œã€ï¼ˆ])', r'\1\n\n\2', text)
            
            # Fix spacing around Japanese punctuation
            text = re.sub(r'\s+([ã€‚ã€ï¼ï¼Ÿã€ã€ï¼‰])', r'\1', text)
            text = re.sub(r'([ã€Œã€ï¼ˆ])\s+', r'\1', text)
            
            # Clean up list items
            text = re.sub(r'^[-ãƒ»]\s*', 'â€¢ ', text, flags=re.MULTILINE)
            
            return text
        except Exception as e:
            logger.error(f"æ–‡ç« æ§‹é€ ã®æ”¹å–„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return text

    def _get_user_friendly_error_message(self, error_msg: str) -> str:
        """Convert technical error messages to user-friendly messages"""
        error_map = {
            'connection': "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
            'timeout': "å¿œç­”å¾…ã¡ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚",
            'quota': "APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
            'invalid': "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèªã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚",
            'empty': "AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã—ãŸã€‚åˆ¥ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã§è©¦ã—ã¦ãã ã•ã„ã€‚"
        }
        
        error_msg = error_msg.lower()
        for key, message in error_map.items():
            if key in error_msg:
                return message
                
        return "äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚"

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((ConnectionError, TimeoutError, Exception))
    )
    def get_transcript(self, url: str) -> str:
        """Get transcript with improved error handling and retries"""
        video_id = self._extract_video_id(url)
        if not video_id:
            raise ValueError("ç„¡åŠ¹ãªYouTube URLã§ã™")
        
        try:
            # Check cache first
            cached_transcript = self.subtitle_cache.get(video_id)
            if cached_transcript:
                logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå­—å¹•ã‚’ä½¿ç”¨ã—ã¾ã™")
                return cached_transcript
            
            transcript = self._get_subtitles_with_priority(video_id)
            if not transcript:
                raise ValueError("å­—å¹•ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å‹•ç”»ã«å­—å¹•ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ã€ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            
            cleaned_transcript = self._clean_text(transcript)
            self.subtitle_cache[video_id] = cleaned_transcript
            return cleaned_transcript
            
        except Exception as e:
            error_msg = f"å­—å¹•å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            raise ValueError(error_msg)

    def _extract_video_id(self, url: str) -> Optional[str]:
        """Extract video ID from YouTube URL"""
        try:
            patterns = [
                r'(?:v=|/v/|youtu\.be/)([^&?/]+)',
                r'(?:embed/|v/)([^/?]+)',
                r'^([^/?]+)$'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, url)
                if match:
                    return match.group(1)
            return None
        except Exception as e:
            logger.error(f"Video IDæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _get_subtitles_with_priority(self, video_id: str) -> Optional[str]:
        """Get subtitles with enhanced error handling and caching"""
        try:
            logger.debug(f"å­—å¹•å–å¾—ã‚’é–‹å§‹: video_id={video_id}")
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            logger.debug(f"TranscriptList ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‹: {type(transcript_list)}")
            
            transcript = None
            error_messages = []
            
            # Try Japanese subtitles first with detailed error logging
            for lang in ['ja', 'ja-JP']:
                try:
                    logger.debug(f"{lang}ã®æ‰‹å‹•ä½œæˆå­—å¹•ã‚’æ¤œç´¢ä¸­...")
                    transcript = transcript_list.find_manually_created_transcript([lang])
                    logger.info(f"{lang}ã®æ‰‹å‹•ä½œæˆå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    break
                except Exception as e:
                    error_messages.append(f"{lang}ã®æ‰‹å‹•ä½œæˆå­—å¹•ã®å–å¾—ã«å¤±æ•—: {str(e)}")
                    try:
                        logger.debug(f"{lang}ã®è‡ªå‹•ç”Ÿæˆå­—å¹•ã‚’æ¤œç´¢ä¸­...")
                        transcript = transcript_list.find_generated_transcript([lang])
                        logger.info(f"{lang}ã®è‡ªå‹•ç”Ÿæˆå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                        break
                    except Exception as e:
                        error_messages.append(f"{lang}ã®è‡ªå‹•ç”Ÿæˆå­—å¹•ã®å–å¾—ã«å¤±æ•—: {str(e)}")

            # Fallback to English if Japanese is not available
            if not transcript:
                logger.debug("æ—¥æœ¬èªå­—å¹•ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€è‹±èªå­—å¹•ã‚’æ¤œç´¢ä¸­...")
                try:
                    transcript = transcript_list.find_manually_created_transcript(['en'])
                    logger.info("è‹±èªã®æ‰‹å‹•ä½œæˆå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                except Exception as e:
                    error_messages.append(f"è‹±èªã®æ‰‹å‹•ä½œæˆå­—å¹•ã®å–å¾—ã«å¤±æ•—: {str(e)}")
                    try:
                        transcript = transcript_list.find_generated_transcript(['en'])
                        logger.info("è‹±èªã®è‡ªå‹•ç”Ÿæˆå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                    except Exception as e:
                        error_messages.append(f"è‹±èªã®è‡ªå‹•ç”Ÿæˆå­—å¹•ã®å–å¾—ã«å¤±æ•—: {str(e)}")

            if not transcript:
                error_detail = "\n".join(error_messages)
                logger.error(f"åˆ©ç”¨å¯èƒ½ãªå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ:\n{error_detail}")
                return None

            # Process transcript segments with improved timing and logging
            try:
                transcript_data = transcript.fetch()
                logger.debug(f"å–å¾—ã—ãŸå­—å¹•ãƒ‡ãƒ¼ã‚¿ã®å‹: {type(transcript_data)}")
                
                if not isinstance(transcript_data, list):
                    raise ValueError("å­—å¹•ãƒ‡ãƒ¼ã‚¿ãŒäºˆæœŸã—ãªã„å½¢å¼ã§ã™")
                
                # Process transcript segments with improved timing and logging
                transcript_segments = []
                current_segment = []
                current_time = 0
                
                for entry in transcript_data:
                    if not isinstance(entry, dict):
                        logger.warning(f"ä¸æ­£ãªå­—å¹•ã‚¨ãƒ³ãƒˆãƒªå½¢å¼: {type(entry)}")
                        continue
                        
                    text = entry.get('text', '').strip()
                    start_time = entry.get('start', 0)
                    
                    # Handle time gaps and segment breaks
                    if start_time - current_time > 5:  # Gap of more than 5 seconds
                        if current_segment:
                            transcript_segments.append(' '.join(current_segment))
                            current_segment = []
                    
                    if text:
                        # Clean up text
                        text = re.sub(r'\[.*?\]', '', text)
                        text = text.strip()
                        
                        # Handle sentence endings
                        if re.search(r'[ã€‚ï¼.ï¼!ï¼Ÿ?]$', text):
                            current_segment.append(text)
                            transcript_segments.append(' '.join(current_segment))
                            current_segment = []
                        else:
                            current_segment.append(text)
                    
                    current_time = start_time + entry.get('duration', 0)
                
                # Add remaining segment
                if current_segment:
                    transcript_segments.append(' '.join(current_segment))

                if not transcript_segments:
                    logger.warning("æœ‰åŠ¹ãªå­—å¹•ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    return None
                    
                return '\n'.join(transcript_segments)

            except Exception as e:
                logger.error(f"å­—å¹•ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                return None

        except Exception as e:
            error_msg = f"å­—å¹•ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            logger.error(error_msg)
            return None
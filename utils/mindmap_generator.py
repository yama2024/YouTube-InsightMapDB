import logging
import hashlib
from typing import Dict, List, Tuple, Optional
import json

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MindMapGenerator:
    def __init__(self):
        self._cache = {}

    def _create_mermaid_mindmap(self, data: Dict) -> str:
        """Generate Mermaid mindmap syntax with enhanced styling and hierarchy"""
        try:
            logger.debug(f"Starting mindmap creation with data structure: {list(data.keys())}")
            lines = ["mindmap"]
            
            # Enhanced style definitions
            lines.extend([
                "  %%{init: {",
                "    'theme': 'base',",
                "    'themeVariables': {",
                "      'primaryColor': '#57C7FF',",
                "      'primaryTextColor': '#000',",
                "      'primaryBorderColor': '#7C0000',",
                "      'lineColor': '#00B5AA',",
                "      'fontSize': '16px'",
                "    },",
                "    'mindmap': {",
                "      'padding': 16,",
                "      'nodeSpacing': 50",
                "    },",
                "    'flowchart': {",
                "      'curve': 'basis',",
                "      'htmlLabels': true,",
                "      'rankSpacing': 80,",
                "      'nodeSpacing': 50",
                "    }",
                "  }}%%",
                "",
                "  classDef root fill:#FF9999,stroke:#FF0000,stroke-width:2px,color:#000",
                "  classDef category fill:#99FF99,stroke:#00FF00,stroke-width:2px,color:#000",
                "  classDef critical fill:#FF7070,stroke:#FF0000,stroke-width:2px,color:#000,font-weight:bold",
                "  classDef important fill:#FFB570,stroke:#FF7F00,stroke-width:2px,color:#000",
                "  classDef normal fill:#70FF70,stroke:#00FF00,stroke-width:1px,color:#000",
                "  classDef auxiliary fill:#70B5FF,stroke:#0000FF,stroke-width:1px,color:#000",
                "  classDef note fill:#FFE070,stroke:#FFD700,stroke-width:1px,color:#000,font-style:italic",
                "  classDef content fill:#FFFFFF,stroke:#CCCCCC,stroke-width:1px,color:#000",
                "  classDef conclusion fill:#FF99CC,stroke:#FF69B4,stroke-width:2px,color:#000,font-weight:bold"
            ])
            
            # Root node with enhanced styling
            overview = self._clean_text(data.get("å‹•ç”»ã®æ¦‚è¦", "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¦‚è¦"))
            if len(overview) > 50:
                overview = overview[:47] + "..."
            lines.append(f"  root((ğŸ“º {overview})):::root")
            logger.debug(f"Added root node: {overview}")
            
            # Process points as primary branches with enhanced styling
            points = data.get("ãƒã‚¤ãƒ³ãƒˆ", [])
            if not points:
                logger.warning("No points found in data")
                return self._create_fallback_mindmap()
                
            logger.debug(f"Processing {len(points)} points")
            categories = self._categorize_points(points)
            
            # Process points by category
            for category, cat_points in categories.items():
                # Add category node
                cat_id = self._get_category_id(category)
                lines.append(f"    {cat_id}[{self._get_category_icon(category)} {category}]:::category")
                
                # Process points in this category
                for i, point in enumerate(cat_points, 1):
                    if not isinstance(point, dict):
                        logger.error(f"Invalid point structure at index {i}")
                        continue
                        
                    title = self._clean_text(point.get("ã‚¿ã‚¤ãƒˆãƒ«", ""))
                    if not title:
                        logger.warning(f"Empty title for point {i}")
                        continue
                    
                    # Style based on importance
                    importance = point.get("é‡è¦åº¦", 3)
                    importance_style = self._get_importance_style(importance)
                    point_id = f"{cat_id}.{i}"
                    
                    # Add point with styled node
                    importance_mark = "ğŸ”¥" if importance >= 4 else "â­" if importance >= 2 else "ãƒ»"
                    lines.append(f"      {point_id}({importance_mark} {title}):::{importance_style}")
                    
                    # Add content with enhanced styling
                    content = self._clean_text(point.get("å†…å®¹", ""))
                    if content:
                        # Create content chunks with better formatting
                        content_parts = self._chunk_content(content)
                        for j, part in enumerate(content_parts, 1):
                            if part.strip():
                                lines.append(f"        {point_id}.{j}[{part}]:::content")
                    
                    # Add supplementary info with distinct styling
                    if "è£œè¶³æƒ…å ±" in point and point["è£œè¶³æƒ…å ±"]:
                        suppl_info = self._clean_text(point["è£œè¶³æƒ…å ±"])
                        if suppl_info:
                            lines.append(f"        {point_id}.s>ğŸ’¡ {suppl_info[:40]}...]:::note")
            
            # Add conclusion with special styling
            conclusion = self._clean_text(data.get("çµè«–", ""))
            if conclusion:
                lines.append("    c{ğŸ’¡ çµè«–}:::conclusion")
                conclusion_parts = self._chunk_content(conclusion)
                for i, part in enumerate(conclusion_parts, 1):
                    if part.strip():
                        lines.append(f"      c.{i}[{part}]:::conclusion-content")
            
            mindmap = "\n".join(lines)
            logger.debug(f"Generated mindmap structure:\n{mindmap}")
            return mindmap
            
        except Exception as e:
            logger.error(f"Error in mindmap creation: {str(e)}", exc_info=True)
            return self._create_fallback_mindmap()

    def _clean_text(self, text: str) -> str:
        """Clean and escape text for Mermaid syntax"""
        if not isinstance(text, str):
            text = str(text)
        return (text.replace('"', "'")
                   .replace("\n", " ")
                   .replace("[", "ã€Œ")
                   .replace("]", "ã€")
                   .replace("(", "ï¼ˆ")
                   .replace(")", "ï¼‰")
                   .replace("<", "ï¼œ")
                   .replace(">", "ï¼")
                   .strip())

    def _create_fallback_mindmap(self, error_details: str = None) -> str:
        """ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å«ã‚€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã®ç”Ÿæˆ"""
        lines = [
            "mindmap",
            "  %%{init: {'theme': 'base'}}%%",
            "  classDef error fill:#FFE6E6,stroke:#FF0000,stroke-width:2px,color:#FF0000",
            "  classDef warning fill:#FFF3E6,stroke:#FFA500,stroke-width:2px,color:#FFA500",
            "  classDef info fill:#E6F3FF,stroke:#0066CC,stroke-width:1px,color:#0066CC",
            "",
            "  root((âš ï¸ ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ç”Ÿæˆã‚¨ãƒ©ãƒ¼)):::error",
            "    error[å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ]:::error",
            f"      details[\"{error_details if error_details else 'ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã®ç”Ÿæˆã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ'}\"]:::warning",
            "    check[ç¢ºèªäº‹é …]:::info",
            "      check.1[å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèª]:::info",
            "      check.2[ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚’ç¢ºèª]:::info",
            "      check.3[ç‰¹æ®Šæ–‡å­—ã®ä½¿ç”¨ã‚’ç¢ºèª]:::info",
            "    solution[å¯¾å‡¦æ–¹æ³•]:::info",
            "      solution.1[ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦å†è©¦è¡Œ]:::info",
            "      solution.2[å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£]:::info",
            "      solution.3[ã‚µãƒãƒ¼ãƒˆã«å•ã„åˆã‚ã›]:::info",
            "    tips[ãƒ’ãƒ³ãƒˆ]:::info",
            "      tips.1[ãƒ‡ãƒ¼ã‚¿å½¢å¼ã¯JSONã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™]:::info",
            "      tips.2[ãƒ†ã‚­ã‚¹ãƒˆã¯é©åˆ‡ãªé•·ã•ã«åã‚ã‚‹]:::info",
            "      tips.3[ç‰¹æ®Šæ–‡å­—ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—]:::info"
        ]
        return "\n".join(lines)

    def _validate_json_structure(self, data: Dict) -> bool:
        """Validate the JSON structure with enhanced validation and logging"""
        try:
            # Log input data structure
            logger.debug(f"Validating data structure: {type(data)}")
            logger.debug(f"Available keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
            
            # Basic type validation
            if not isinstance(data, dict):
                logger.error(f"Invalid data type: expected dict, got {type(data)}")
                return False
            
            # Required keys validation with content length check
            required_keys = ["å‹•ç”»ã®æ¦‚è¦", "ãƒã‚¤ãƒ³ãƒˆ", "çµè«–"]
            for key in required_keys:
                if key not in data:
                    logger.error(f"Missing required key: {key}")
                    return False
                value = data[key]
                if key == "å‹•ç”»ã®æ¦‚è¦":
                    if not isinstance(value, str) or len(value.strip()) < 10:
                        logger.error(f"Invalid overview: must be string with min length 10, got {type(value)}")
                        return False
                elif key == "çµè«–":
                    if not isinstance(value, str) or len(value.strip()) < 10:
                        logger.error(f"Invalid conclusion: must be string with min length 10, got {type(value)}")
                        return False
            
            # Validate points array
            points = data.get("ãƒã‚¤ãƒ³ãƒˆ", [])
            if not isinstance(points, list) or not points:
                logger.error(f"Points must be non-empty list, got {type(points)}")
                return False
            
            # Validate each point structure
            for i, point in enumerate(points):
                if not self._validate_point_structure(point, i):
                    return False
            
            # Additional validation for nested structures
            if "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" in data:
                keywords = data["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"]
                if not isinstance(keywords, list):
                    logger.error("Keywords must be a list")
                    return False
                for i, keyword in enumerate(keywords):
                    if not isinstance(keyword, dict) or "ç”¨èª" not in keyword or "èª¬æ˜" not in keyword:
                        logger.error(f"Invalid keyword structure at index {i}")
                        return False
            
            logger.info("JSON structure validation successful")
            logger.debug("All validations passed successfully")
            return True
            
        except Exception as e:
            logger.error(f"Validation error: {str(e)}", exc_info=True)
            return False
            
    def _validate_point_structure(self, point: Dict, index: int) -> bool:
        """Validate individual point structure"""
        if not isinstance(point, dict):
            logger.error(f"Point {index} is not a dictionary")
            return False
            
        # Required fields validation
        required_fields = {
            "ã‚¿ã‚¤ãƒˆãƒ«": (str, 1, 100),  # (type, min_length, max_length)
            "å†…å®¹": (str, 10, 1000),
            "é‡è¦åº¦": (int, 1, 5)
        }
        
        for field, (expected_type, min_val, max_val) in required_fields.items():
            value = point.get(field)
            if field not in point:
                logger.error(f"Point {index} missing required field: {field}")
                return False
                
            if not isinstance(value, expected_type):
                logger.error(f"Point {index} field {field} has wrong type: expected {expected_type}, got {type(value)}")
                return False
                
            if expected_type == str and value is not None:
                stripped_value = value.strip()
                if len(stripped_value) < min_val or len(stripped_value) > max_val:
                    logger.error(f"Point {index} field {field} length out of range: {len(stripped_value)} not in [{min_val}, {max_val}]")
                    return False
                
            if expected_type == int and (value < min_val or value > max_val):
                logger.error(f"Point {index} field {field} value out of range: {value} not in [{min_val}, {max_val}]")
                return False
        
        return True
            
    def _categorize_points(self, points: List[Dict]) -> Dict:
        """ãƒã‚¤ãƒ³ãƒˆã‚’ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«åˆ†é¡ã™ã‚‹"""
        categories = {}
        
        for point in points:
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ±ºå®šï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æ¨æ¸¬ï¼‰
            title = point.get("ã‚¿ã‚¤ãƒˆãƒ«", "").lower()
            content = point.get("å†…å®¹", "").lower()
            importance = point.get("é‡è¦åº¦", 3)
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
            if any(key in title or key in content for key in ["æ¦‚è¦", "ã¾ã¨ã‚", "å°å…¥"]):
                category = "æ¦‚è¦ãƒ»å°å…¥"
            elif any(key in title or key in content for key in ["æ‰‹é †", "æ–¹æ³•", "ã‚„ã‚Šæ–¹"]):
                category = "æ‰‹é †ãƒ»æ–¹æ³•"
            elif any(key in title or key in content for key in ["çµæœ", "åŠ¹æœ", "æˆæœ"]):
                category = "çµæœãƒ»åŠ¹æœ"
            elif importance >= 4:
                category = "é‡è¦ãƒã‚¤ãƒ³ãƒˆ"
            else:
                category = "ãã®ä»–"
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ 
            if category not in categories:
                categories[category] = []
            categories[category].append(point)
            
        return categories

    def _get_category_id(self, category: str) -> str:
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼åã‹ã‚‰ä¸€æ„ã®IDã‚’ç”Ÿæˆ"""
        # ç‰¹æ®Šæ–‡å­—ã‚’å‡¦ç†ã—ã€çŸ­ã„ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ
        safe_category = "".join(c for c in category if c.isalnum())
        hash_obj = hashlib.md5(safe_category.encode())
        return f"cat_{hash_obj.hexdigest()[:6]}"

    def _get_category_icon(self, category: str) -> str:
        """ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«å¿œã˜ãŸé©åˆ‡ãªã‚¢ã‚¤ã‚³ãƒ³ã‚’å‰²ã‚Šå½“ã¦"""
        icons = {
            "æ¦‚è¦ãƒ»å°å…¥": "ğŸ“",
            "æ‰‹é †ãƒ»æ–¹æ³•": "ğŸ“Œ",
            "çµæœãƒ»åŠ¹æœ": "ğŸ¯",
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": "â­",
            "ãã®ä»–": "ğŸ’¡"
        }
        return icons.get(category, "â€¢")

    def _get_importance_style(self, importance: int) -> str:
        """é‡è¦åº¦ã«å¿œã˜ãŸã‚¹ã‚¿ã‚¤ãƒ«ã‚¯ãƒ©ã‚¹ã‚’å‰²ã‚Šå½“ã¦"""
        if importance >= 5:
            return "critical"
        elif importance >= 4:
            return "important"
        elif importance >= 3:
            return "normal"
        return "auxiliary"
    def generate_mindmap(self, text: str) -> Tuple[str, bool]:
        """Generate a mindmap from the analyzed text with enhanced validation"""
        try:
            if not text or not isinstance(text, str):
                logger.error(f"Invalid input text type: {type(text)}")
                return self._create_fallback_mindmap(), False

            logger.info(f"Generating mindmap for text of length: {len(text)}")
            
            # Check cache with reliable key generation
            cache_key = hash(f"{text}_{self.__class__.__name__}")
            if cache_key in self._cache:
                logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’å–å¾—ã—ã¾ã—ãŸ")
                cached_content = self._cache[cache_key]
                logger.debug(f"Cached mindmap length: {len(cached_content)}")
                return cached_content, True

            # Parse and validate JSON
            try:
                logger.debug("Attempting to parse JSON data")
                data = json.loads(text)
                logger.info("JSON parsing successful")
                
                if not self._validate_json_structure(data):
                    logger.warning("Invalid JSON structure detected, using fallback structure")
                    logger.debug(f"Received data structure: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
                    data = {
                        "å‹•ç”»ã®æ¦‚è¦": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¦ç´„",
                        "ãƒã‚¤ãƒ³ãƒˆ": [
                            {
                                "ã‚¿ã‚¤ãƒˆãƒ«": "ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ",
                                "å†…å®¹": "å‹•ç”»ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ",
                                "é‡è¦åº¦": 3
                            }
                        ],
                        "çµè«–": "å†…å®¹ã‚’ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ"
                    }
                    logger.info("Using fallback data structure")
            except json.JSONDecodeError as e:
                logger.warning("Invalid JSON format, creating basic structure")
                data = {
                    "å‹•ç”»ã®æ¦‚è¦": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¦‚è¦",
                    "ãƒã‚¤ãƒ³ãƒˆ": [{
                        "ã‚¿ã‚¤ãƒˆãƒ«": "æ¦‚è¦",
                        "å†…å®¹": text[:100] + "..." if len(text) > 100 else text,
                        "é‡è¦åº¦": 3
                    }],
                    "çµè«–": "ãƒ†ã‚­ã‚¹ãƒˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ"
                }
                
            # Generate mindmap with validated data
            mermaid_syntax = self._create_mermaid_mindmap(data)
            
            # Cache only valid results
            if mermaid_syntax and mermaid_syntax.count('\n') > 2:
                self._cache[cache_key] = mermaid_syntax
                logger.info("æ–°ã—ã„ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")
                return mermaid_syntax, True
            
            logger.warning("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãŒç„¡åŠ¹ã§ã™")
            return self._create_fallback_mindmap(), False
            
        except Exception as e:
            logger.error(f"Error processing text: {str(e)}", exc_info=True)
            return self._create_fallback_mindmap(), False

    def _validate_data(self, text: str) -> Optional[Dict]:
        """Validate and parse the input text data"""
        try:
            # Parse JSON data
            data = json.loads(text)
            
            # Validate structure
            if not self._validate_json_structure(data):
                return None
                
            return data
        except json.JSONDecodeError:
            logger.error("Invalid JSON format")
            return None
        except Exception as e:
            logger.error(f"Data validation error: {str(e)}")
            return None

    def _categorize_points(self, points: List[Dict]) -> Dict:
        """Categorize points based on their content and importance"""
        categories = {
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": [],
            "ä¸»è¦ãªæƒ…å ±": [],
            "è£œè¶³èª¬æ˜": []
        }
        
        for point in points:
            importance = point.get("é‡è¦åº¦", 3)
            if importance >= 4:
                categories["é‡è¦ãƒã‚¤ãƒ³ãƒˆ"].append(point)
            elif importance >= 2:
                categories["ä¸»è¦ãªæƒ…å ±"].append(point)
            else:
                categories["è£œè¶³èª¬æ˜"].append(point)
                
        return {k: v for k, v in categories.items() if v}  # Only return non-empty categories

    def _get_category_id(self, category: str) -> str:
        """Generate a unique ID for each category"""
        category_ids = {
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": "key",
            "ä¸»è¦ãªæƒ…å ±": "main",
            "è£œè¶³èª¬æ˜": "sub"
        }
        return category_ids.get(category, "misc")

    def _get_category_icon(self, category: str) -> str:
        """Get appropriate icon for each category"""
        icons = {
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": "ğŸ¯",
            "ä¸»è¦ãªæƒ…å ±": "ğŸ“Œ",
            "è£œè¶³èª¬æ˜": "â„¹ï¸"
        }
        return icons.get(category, "â€¢")

    def _get_importance_style(self, importance: int) -> str:
        """Get style class based on importance level"""
        if importance >= 4:
            return "critical"
        elif importance >= 3:
            return "important"
        elif importance >= 2:
            return "normal"
        return "auxiliary"

    def _chunk_content(self, content: str, chunk_size: int = 40) -> List[str]:
        """ã‚ˆã‚Šè‡ªç„¶ãªæ–‡ç« ã®åˆ†å‰²ã‚’å®Ÿç¾ã™ã‚‹æ”¹å–„ç‰ˆãƒãƒ£ãƒ³ã‚¯å‡¦ç†"""
        if len(content) <= chunk_size:
            return [content]

        # å¥èª­ç‚¹ã«ã‚ˆã‚‹åˆ†å‰²ã‚’å„ªå…ˆ
        sentence_delimiters = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼', '\n']
        parts = []
        current_chunk = ""
        buffer = ""

        for char in content:
            buffer += char
            
            # å¥èª­ç‚¹ã§åŒºåˆ‡ã‚‹
            if char in sentence_delimiters:
                if len(current_chunk) + len(buffer) <= chunk_size:
                    current_chunk += buffer
                    buffer = ""
                else:
                    if current_chunk:
                        parts.append(current_chunk)
                    current_chunk = buffer
                    buffer = ""
            
            # ãƒãƒƒãƒ•ã‚¡ãŒä¸€å®šã‚µã‚¤ã‚ºã‚’è¶…ãˆãŸã‚‰å¼·åˆ¶åˆ†å‰²
            if len(buffer) >= chunk_size:
                if current_chunk:
                    parts.append(current_chunk)
                parts.append(buffer.strip())
                current_chunk = ""
                buffer = ""

        # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†
        remaining = current_chunk + buffer
        if remaining:
            if len(remaining) <= chunk_size:
                parts.append(remaining)
            else:
                words = remaining.split()
                current_chunk = ""
                for word in words:
                    if len(current_chunk) + len(word) + 1 <= chunk_size:
                        current_chunk += (" " + word if current_chunk else word)
                    else:
                        if current_chunk:
                            parts.append(current_chunk)
                        current_chunk = word
                if current_chunk:
                    parts.append(current_chunk)

        return [part.strip() for part in parts if part.strip()]

    def generate_mindmap(self, text: str) -> Tuple[str, bool]:
        """Generate a mindmap from the given text"""
        try:
            cache_key = hashlib.md5(text.encode()).hexdigest()
            if cache_key in self._cache:
                logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’å–å¾—ã—ã¾ã—ãŸ")
                return self._cache[cache_key], True

            data = self._validate_data(text)
            if not data:
                logger.error("ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return self._create_fallback_mindmap(), False

            # Generate mindmap with validated data
            mermaid_syntax = self._create_mermaid_mindmap(data)
            
            # Cache only valid results
            if mermaid_syntax and mermaid_syntax.count('\n') > 2:
                self._cache[cache_key] = mermaid_syntax
                logger.info("æ–°ã—ã„ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")
                return mermaid_syntax, True
            
            logger.warning("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãŒç„¡åŠ¹ã§ã™")
            return self._create_fallback_mindmap(), False
            
        except Exception as e:
            logger.error(f"ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return self._create_fallback_mindmap(), False

import logging
import hashlib
from typing import Dict, List, Tuple, Optional
import json

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MindMapGenerator:
    def __init__(self):
        self._cache = {}

    def _create_mermaid_mindmap(self, data: Dict) -> str:
        """Generate Mermaid mindmap syntax with enhanced styling and hierarchy"""
        try:
            logger.debug(f"Starting mindmap creation with data structure: {list(data.keys())}")
            lines = ["mindmap"]
            
            # Define style classes
            lines.extend([
                "  %%{init: {'theme': 'forest'}}%%",
                "  %%{init: {'flowchart': {'curve': 'monotoneX'}}}%%"
            ])
            
            # Root node with enhanced styling
            overview = self._clean_text(data.get("å‹•ç”»ã®æ¦‚è¦", "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¦‚è¦"))
            if len(overview) > 50:
                overview = overview[:47] + "..."
            lines.append(f"  root((ğŸ“º {overview})):::root")
            logger.debug(f"Added root node: {overview}")
            
            # Process points as primary branches with enhanced styling
            points = data.get("ãƒã‚¤ãƒ³ãƒˆ", [])
            if not points:
                logger.warning("No points found in data")
                return self._create_fallback_mindmap()
                
            logger.debug(f"Processing {len(points)} points")
            categories = self._categorize_points(points)
            
            # Process points by category
            for category, cat_points in categories.items():
                # Add category node
                cat_id = self._get_category_id(category)
                lines.append(f"    {cat_id}[{self._get_category_icon(category)} {category}]:::category")
                
                # Process points in this category
                for i, point in enumerate(cat_points, 1):
                    if not isinstance(point, dict):
                        logger.error(f"Invalid point structure at index {i}")
                        continue
                        
                    title = self._clean_text(point.get("ã‚¿ã‚¤ãƒˆãƒ«", ""))
                    if not title:
                        logger.warning(f"Empty title for point {i}")
                        continue
                    
                    # Style based on importance
                    importance = point.get("é‡è¦åº¦", 3)
                    importance_style = self._get_importance_style(importance)
                    point_id = f"{cat_id}.{i}"
                    
                    # Add point with styled node
                    importance_mark = "ğŸ”¥" if importance >= 4 else "â­" if importance >= 2 else "ãƒ»"
                    lines.append(f"      {point_id}({importance_mark} {title}):::{importance_style}")
                    
                    # Add content with enhanced styling
                    content = self._clean_text(point.get("å†…å®¹", ""))
                    if content:
                        # Create content chunks with better formatting
                        content_parts = self._chunk_content(content)
                        for j, part in enumerate(content_parts, 1):
                            if part.strip():
                                lines.append(f"        {point_id}.{j}[{part}]:::content")
                    
                    # Add supplementary info with distinct styling
                    if "è£œè¶³æƒ…å ±" in point and point["è£œè¶³æƒ…å ±"]:
                        suppl_info = self._clean_text(point["è£œè¶³æƒ…å ±"])
                        if suppl_info:
                            lines.append(f"        {point_id}.s>ğŸ’¡ {suppl_info[:40]}...]:::note")
            
            # Add conclusion with special styling
            conclusion = self._clean_text(data.get("çµè«–", ""))
            if conclusion:
                lines.append("    c{ğŸ’¡ çµè«–}:::conclusion")
                conclusion_parts = self._chunk_content(conclusion)
                for i, part in enumerate(conclusion_parts, 1):
                    if part.strip():
                        lines.append(f"      c.{i}[{part}]:::conclusion-content")
            
            mindmap = "\n".join(lines)
            logger.debug(f"Generated mindmap structure:\n{mindmap}")
            return mindmap
            
        except Exception as e:
            logger.error(f"Error in mindmap creation: {str(e)}", exc_info=True)
            return self._create_fallback_mindmap()

    def _clean_text(self, text: str) -> str:
        """Clean and escape text for Mermaid syntax"""
        if not isinstance(text, str):
            text = str(text)
        return (text.replace('"', "'")
                   .replace("\n", " ")
                   .replace("[", "ã€Œ")
                   .replace("]", "ã€")
                   .replace("(", "ï¼ˆ")
                   .replace(")", "ï¼‰")
                   .replace("<", "ï¼œ")
                   .replace(">", "ï¼")
                   .strip())

    def _create_fallback_mindmap(self) -> str:
        """Create a more informative fallback mindmap when generation fails"""
        return """mindmap
  root[ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è§£æçµæœ]
    1[âš ï¸ å‡¦ç†çŠ¶æ…‹]
      1.1[ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã®ç”Ÿæˆã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ]
      1.2[ä»¥ä¸‹ã‚’ã”ç¢ºèªãã ã•ã„]
        1.2.1[ãƒ»å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼]
        1.2.2[ãƒ»ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•]
        1.2.3[ãƒ»ç‰¹æ®Šæ–‡å­—ã®ä½¿ç”¨]
    2[ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—]
      2.1[ãƒ»ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°]
      2.2[ãƒ»å…¥åŠ›ã‚’ç¢ºèª]
      2.3[ãƒ»å†åº¦å®Ÿè¡Œ]"""

    def _validate_json_structure(self, data: Dict) -> bool:
        """Validate the JSON structure with enhanced validation and logging"""
        try:
            # Log input data structure
            logger.debug(f"Validating data structure: {type(data)}")
            logger.debug(f"Available keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
            
            # Basic type validation
            if not isinstance(data, dict):
                logger.error(f"Invalid data type: expected dict, got {type(data)}")
                return False
            
            # Required keys validation with content length check
            required_keys = ["å‹•ç”»ã®æ¦‚è¦", "ãƒã‚¤ãƒ³ãƒˆ", "çµè«–"]
            for key in required_keys:
                if key not in data:
                    logger.error(f"Missing required key: {key}")
                    return False
                value = data[key]
                if key == "å‹•ç”»ã®æ¦‚è¦":
                    if not isinstance(value, str) or len(value.strip()) < 10:
                        logger.error(f"Invalid overview: must be string with min length 10, got {type(value)}")
                        return False
                elif key == "çµè«–":
                    if not isinstance(value, str) or len(value.strip()) < 10:
                        logger.error(f"Invalid conclusion: must be string with min length 10, got {type(value)}")
                        return False
            
            # Validate points array
            points = data.get("ãƒã‚¤ãƒ³ãƒˆ", [])
            if not isinstance(points, list) or not points:
                logger.error(f"Points must be non-empty list, got {type(points)}")
                return False
            
            # Validate each point structure
            for i, point in enumerate(points):
                if not self._validate_point_structure(point, i):
                    return False
            
            # Additional validation for nested structures
            if "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰" in data:
                keywords = data["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"]
                if not isinstance(keywords, list):
                    logger.error("Keywords must be a list")
                    return False
                for i, keyword in enumerate(keywords):
                    if not isinstance(keyword, dict) or "ç”¨èª" not in keyword or "èª¬æ˜" not in keyword:
                        logger.error(f"Invalid keyword structure at index {i}")
                        return False
            
            logger.info("JSON structure validation successful")
            logger.debug("All validations passed successfully")
            return True
            
        except Exception as e:
            logger.error(f"Validation error: {str(e)}", exc_info=True)
            return False
            
    def _validate_point_structure(self, point: Dict, index: int) -> bool:
        """Validate individual point structure"""
        if not isinstance(point, dict):
            logger.error(f"Point {index} is not a dictionary")
            return False
            
        # Required fields validation
        required_fields = {
            "ã‚¿ã‚¤ãƒˆãƒ«": (str, 1, 100),  # (type, min_length, max_length)
            "å†…å®¹": (str, 10, 1000),
            "é‡è¦åº¦": (int, 1, 5)
        }
        
        for field, (expected_type, min_val, max_val) in required_fields.items():
            value = point.get(field)
            if field not in point:
                logger.error(f"Point {index} missing required field: {field}")
                return False
                
            if not isinstance(value, expected_type):
                logger.error(f"Point {index} field {field} has wrong type: expected {expected_type}, got {type(value)}")
                return False
                
            if expected_type == str and value is not None:
                stripped_value = value.strip()
                if len(stripped_value) < min_val or len(stripped_value) > max_val:
                    logger.error(f"Point {index} field {field} length out of range: {len(stripped_value)} not in [{min_val}, {max_val}]")
                    return False
                
            if expected_type == int and (value < min_val or value > max_val):
                logger.error(f"Point {index} field {field} value out of range: {value} not in [{min_val}, {max_val}]")
                return False
        
        return True
            
    def generate_mindmap(self, text: str) -> Tuple[str, bool]:
        """Generate a mindmap from the analyzed text with enhanced validation"""
        try:
            if not text or not isinstance(text, str):
                logger.error(f"Invalid input text type: {type(text)}")
                return self._create_fallback_mindmap(), False

            logger.info(f"Generating mindmap for text of length: {len(text)}")
            
            # Check cache with reliable key generation
            cache_key = hash(f"{text}_{self.__class__.__name__}")
            if cache_key in self._cache:
                logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’å–å¾—ã—ã¾ã—ãŸ")
                cached_content = self._cache[cache_key]
                logger.debug(f"Cached mindmap length: {len(cached_content)}")
                return cached_content, True

            # Parse and validate JSON
            try:
                logger.debug("Attempting to parse JSON data")
                data = json.loads(text)
                logger.info("JSON parsing successful")
                
                if not self._validate_json_structure(data):
                    logger.warning("Invalid JSON structure detected, using fallback structure")
                    logger.debug(f"Received data structure: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
                    data = {
                        "å‹•ç”»ã®æ¦‚è¦": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¦ç´„",
                        "ãƒã‚¤ãƒ³ãƒˆ": [
                            {
                                "ã‚¿ã‚¤ãƒˆãƒ«": "ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ",
                                "å†…å®¹": "å‹•ç”»ã®å†…å®¹ã‚’ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ",
                                "é‡è¦åº¦": 3
                            }
                        ],
                        "çµè«–": "å†…å®¹ã‚’ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ"
                    }
                    logger.info("Using fallback data structure")
            except json.JSONDecodeError as e:
                logger.warning("Invalid JSON format, creating basic structure")
                data = {
                    "å‹•ç”»ã®æ¦‚è¦": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¦‚è¦",
                    "ãƒã‚¤ãƒ³ãƒˆ": [{
                        "ã‚¿ã‚¤ãƒˆãƒ«": "æ¦‚è¦",
                        "å†…å®¹": text[:100] + "..." if len(text) > 100 else text,
                        "é‡è¦åº¦": 3
                    }],
                    "çµè«–": "ãƒ†ã‚­ã‚¹ãƒˆã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ"
                }
                
            # Generate mindmap with validated data
            mermaid_syntax = self._create_mermaid_mindmap(data)
            
            # Cache only valid results
            if mermaid_syntax and mermaid_syntax.count('\n') > 2:
                self._cache[cache_key] = mermaid_syntax
                logger.info("æ–°ã—ã„ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")
                return mermaid_syntax, True
            
            logger.warning("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãŒç„¡åŠ¹ã§ã™")
            return self._create_fallback_mindmap(), False
            
        except Exception as e:
            logger.error(f"Error processing text: {str(e)}", exc_info=True)
            return self._create_fallback_mindmap(), False

    def _validate_data(self, text: str) -> Optional[Dict]:
        """Validate and parse the input text data"""
        try:
            # Parse JSON data
            data = json.loads(text)
            
            # Validate structure
            if not self._validate_json_structure(data):
                return None
                
            return data
        except json.JSONDecodeError:
            logger.error("Invalid JSON format")
            return None
        except Exception as e:
            logger.error(f"Data validation error: {str(e)}")
            return None

    def _categorize_points(self, points: List[Dict]) -> Dict:
        """Categorize points based on their content and importance"""
        categories = {
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": [],
            "ä¸»è¦ãªæƒ…å ±": [],
            "è£œè¶³èª¬æ˜": []
        }
        
        for point in points:
            importance = point.get("é‡è¦åº¦", 3)
            if importance >= 4:
                categories["é‡è¦ãƒã‚¤ãƒ³ãƒˆ"].append(point)
            elif importance >= 2:
                categories["ä¸»è¦ãªæƒ…å ±"].append(point)
            else:
                categories["è£œè¶³èª¬æ˜"].append(point)
                
        return {k: v for k, v in categories.items() if v}  # Only return non-empty categories

    def _get_category_id(self, category: str) -> str:
        """Generate a unique ID for each category"""
        category_ids = {
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": "key",
            "ä¸»è¦ãªæƒ…å ±": "main",
            "è£œè¶³èª¬æ˜": "sub"
        }
        return category_ids.get(category, "misc")

    def _get_category_icon(self, category: str) -> str:
        """Get appropriate icon for each category"""
        icons = {
            "é‡è¦ãƒã‚¤ãƒ³ãƒˆ": "ğŸ¯",
            "ä¸»è¦ãªæƒ…å ±": "ğŸ“Œ",
            "è£œè¶³èª¬æ˜": "â„¹ï¸"
        }
        return icons.get(category, "â€¢")

    def _get_importance_style(self, importance: int) -> str:
        """Get style class based on importance level"""
        if importance >= 4:
            return "critical"
        elif importance >= 3:
            return "important"
        elif importance >= 2:
            return "normal"
        return "auxiliary"

    def _chunk_content(self, content: str, chunk_size: int = 40) -> List[str]:
        """Chunk content into readable parts with smart splitting"""
        if len(content) <= chunk_size:
            return [content]
            
        parts = []
        current_chunk = ""
        words = content.split()
        
        for word in words:
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += (" " + word if current_chunk else word)
            else:
                if current_chunk:
                    parts.append(current_chunk)
                current_chunk = word
                
        if current_chunk:
            parts.append(current_chunk)
            
        return parts

    def generate_mindmap(self, text: str) -> Tuple[str, bool]:
        """Generate a mindmap from the given text"""
        try:
            cache_key = hashlib.md5(text.encode()).hexdigest()
            if cache_key in self._cache:
                logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’å–å¾—ã—ã¾ã—ãŸ")
                return self._cache[cache_key], True

            data = self._validate_data(text)
            if not data:
                logger.error("ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return self._create_fallback_mindmap(), False

            # Generate mindmap with validated data
            mermaid_syntax = self._create_mermaid_mindmap(data)
            
            # Cache only valid results
            if mermaid_syntax and mermaid_syntax.count('\n') > 2:
                self._cache[cache_key] = mermaid_syntax
                logger.info("æ–°ã—ã„ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã‚’ç”Ÿæˆã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã—ãŸ")
                return mermaid_syntax, True
            
            logger.warning("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãŒç„¡åŠ¹ã§ã™")
            return self._create_fallback_mindmap(), False
            
        except Exception as e:
            logger.error(f"ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return self._create_fallback_mindmap(), False
